{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "from pdb import set_trace\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666666\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def tokenize_py(text):\n",
    "    \"\"\"\n",
    "    Tokenizes py text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    #print(text)\n",
    "    return text.split(' ')\n",
    "def tokenize_ch(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    t = list(text)#@.split('')\n",
    "    #print(t)\n",
    "    return t #list(text)\n",
    "SRC = Field(tokenize=tokenize_py, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)\n",
    "TRG = Field(tokenize=tokenize_ch, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TranslationDataset('./data/ai_shell_train',('.py','.han'),(SRC,TRG))\n",
    "valid_data = TranslationDataset('./data/ai_shell_dev',('.py','.han'),(SRC,TRG))\n",
    "test_data = TranslationDataset('./data/ai_shell_test',('.py','.han'),(SRC,TRG))\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "\n",
    "#train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE,\n",
    "     device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim,n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers,\n",
    "                           dropout = 0,bidirectional=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim*2+emb_dim, 512)\n",
    "        self.conv1 = nn.Conv2d(1,1,(7,3),padding=(3,1))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.conv2 = nn.Conv2d(1,1,(7,3),padding=(3,1))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(1)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "        #self.relu = nn.LeakyReLU()\n",
    "        #s#elf.softmax = nn.Softmax(dim=-1)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(src)\n",
    "        max_len = src.shape[0]\n",
    "        #embedded = [src sent len, batch size, emb dim]\n",
    "       \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        out2 = torch.cat([outputs,embedded],-1)\n",
    "        #out3  = self.fc(out2)\n",
    "        out  = self.fc(out2)\n",
    "        out = torch.unsqueeze(out,1)\n",
    "       \n",
    "        out = self.conv1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.bn2(out)       \n",
    "        \n",
    "        out = torch.squeeze(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.log_softmax(out)\n",
    "       \n",
    "        \n",
    "        return out#, hidden, cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_vocab_size = len(SRC.vocab)\n",
    "ch_vocab_size = len(TRG.vocab)\n",
    "emb_dim = 512\n",
    "#DEC_EMB_DIM = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = Model(py_vocab_size, emb_dim, hidden_dim,ch_vocab_size, n_layers).to(device)\n",
    "#dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "#model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model = model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,798,087 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index = PAD_IDX)\n",
    "import tqdm\n",
    "\n",
    "tok = ['<eos>','<unk>','<sos>','<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pre_target(output,target,show_txt=True):\n",
    "    pred = torch.argmax(output,-1)\n",
    "    i = 0\n",
    "    for p, t in zip(pred.cpu().numpy(),target.cpu().numpy()):    \n",
    "       \n",
    "        ss = [TRG.vocab.itos[i] for i in p]\n",
    "        ss = [_s for _s in ss if _s not in tok]\n",
    "        s_text = ''.join(ss)\n",
    "        \n",
    "        tt = [TRG.vocab.itos[i] for i in t]\n",
    "        tt = [_t for _t in tt if _t not in tok]\n",
    "        \n",
    "        t_text = ''.join(tt)\n",
    "        \n",
    "        if i ==0 and show_txt:\n",
    "            print('pred:',s_text[:len(t_text)])    \n",
    "            print('true:',t_text)\n",
    "        i+=1\n",
    "        if len(ss) !=0:\n",
    "            acc = np.sum([s==t for s,t in zip(ss,tt)])/(len(tt))\n",
    "        else:\n",
    "            acc = 0\n",
    "        \n",
    "        return acc\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b33049ba6ef401d843b3f315433e21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=885), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 并称今天\n",
      "true: 并称今天\n",
      "pred: 年龄或大获小的孩子\n",
      "true: 年龄或大或小的孩子\n",
      "pred: 一位商场场内部人士称\n",
      "true: 一位商场场内部人士称\n",
      "pred: 而不是单独的一家来垄断\n",
      "true: 而不是单独的一家来垄断\n",
      "pred: 京华时报讯记者张然昨天\n",
      "true: 京华时报讯记者张然昨天\n",
      "pred: 房贷的发放需要一定的周期\n",
      "true: 房贷的发放需要一定的周期\n",
      "pred: 这次毕竟是在家门口备战比赛\n",
      "true: 这次毕竟是在家门口备战比赛\n",
      "pred: 向他确认了这是一款工程测试机\n",
      "true: 向他确认了这是一款工程测试机\n",
      "pred: 警方认定他的死是被李某殴打所致\n",
      "true: 警方认定他的死是被李某殴打所致\n",
      "pred: 孙河板块现在共有四个别墅项目在售\n",
      "true: 孙河板块现在共有四个别墅项目在售\n",
      "pred: 合作包括你使用一亿元向唐人影视增资\n",
      "true: 合作包括拟使用一亿元向唐人影视增资\n",
      "pred: 同时都都宝城市一卡通网上充付平台上线\n",
      "true: 同时都都宝城市一卡通网上充付平台上线\n",
      "pred: 这名运动员曾获得二零零零年悉尼奥运会金牌\n",
      "true: 这名运动员曾获得二零零零年悉尼奥运会金牌\n",
      "pred: 把住宅交给万科万科聚交三好住宅和城市配套服务\n",
      "true: 把住宅交给万科万科聚焦三好住宅和城市配套服务\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print('evaluating ....')\n",
    "    val_acc = 0\n",
    "    pbar = tqdm.tqdm_notebook(total=len(iterator))\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, batch in enumerate(iterator):\n",
    "            pbar.update(1)\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src)\n",
    "            acc = compare_pre_target(output.detach(),trg.detach(),i % 64==0)\n",
    "            \n",
    "            #output = [batch size, trg sent len - 1, output dim]\n",
    "            #trg = [batch size, trg sent len]\n",
    "            #if i %32 ==0:\n",
    "               # compare_pre_target(output,trg)\n",
    "            output = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg.contiguous().view(-1)#[:,1:]\n",
    "            \n",
    "            val_acc = (val_acc*i + acc)/(i+1)\n",
    "            msg = 'val acc: {:.3}'.format(val_acc)\n",
    "            #output = [batch size * trg sent len - 1, output dim]\n",
    "            #trg = [batch size * trg sent len - 1]\n",
    "            \n",
    "            pbar.set_description_str(msg)\n",
    "    print('done')    \n",
    "    return val_acc\n",
    "\n",
    "val_acc = evaluate(model, valid_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "grad_clip = 1.0\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'py_to_han')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa4eb22b0844a0bcbbd3a6b6d10dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3098), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 逆向车辆行驶方向跑\n",
      "true: 逆向车辆行驶方向跑\n",
      "pred: 经济参考报记者近日在多地走访了解到\n",
      "true: 经济参考报记者近日在多地走访了解到\n",
      "pred: 苹果和三星这对冤家\n",
      "true: 苹果和三星这对冤家\n",
      "pred: 在基金托管职责履行内控制度建设方面\n",
      "true: 在基金托管职责履行内控制度建设方面\n",
      "pred: 一月公寓豪宅共成交三百套\n",
      "true: 一月公寓豪宅共成交三百套\n",
      "pred: 学校教室确实存在甲醛和氨不同程度超标的情况\n",
      "true: 学校教室确实存在甲醛和氨不同程度超标的情况\n",
      "pred: 由于绿地还未整体上市\n",
      "true: 由于绿地还未整体上市\n",
      "pred: 转而做生意岂料杀出新血路\n",
      "true: 转而做生意岂料杀出新血路\n",
      "pred: 而今天这么多带有类似生活理念的人齐聚一堂\n",
      "true: 而今天这么多带有类似生活理念的人齐聚一堂\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5daa7baf9937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    bar = tqdm.tqdm_notebook(total=len(train_iterator))\n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        bar.update(1)\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        if trg.shape[0] ==0:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src)\n",
    "        \n",
    "        #if i %1024==0:\n",
    "        show_txt=(i%128==0)\n",
    "        acc = compare_pre_target(output.detach(),trg.detach(),show_txt)\n",
    "            \n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[:].view(-1, output.shape[-1])\n",
    "        trg = trg[:].view(-1)\n",
    "        \n",
    "        if trg.shape[0] ==0:\n",
    "            continue\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss = (epoch_loss*i + loss.item())/(i+1)\n",
    "        epoch_acc = (epoch_acc*i + acc)/(i+1)\n",
    "        \n",
    "        msg = 'loss:{:.5},acc:{:.5}'.format(epoch_loss,epoch_acc)\n",
    "        bar.set_description_str(msg)\n",
    "        \n",
    "  #  train_loss = epoch_loss\n",
    "    val_acc = evaluate(model, train_iterator, criterion)\n",
    "    \n",
    "    \n",
    "    optimizer.param_groups[0]['lr'] *= 0.95\n",
    "    print('lr:',optimizer.param_groups[0]['lr'])\n",
    "    if val_acc > best_val_acc:\n",
    "        model_path = MODEL_SAVE_PATH + 'val_acc{:.3}.pth'.format(val_acc)\n",
    "        \n",
    "        print('validation acc increased from {} to {},saving model to {}'.format(best_val_acc,val_acc,\n",
    "              model_path))\n",
    "        \n",
    "        best_val_acc = val_acc\n",
    "       # torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
